# Kafka Curriculum Plan - 6-Hour Hands-On Course

## ðŸ“‹ Executive Summary

**Goal:** Transform the existing Kafka IoT vehicle monitoring project into a 6-hour beginner-friendly curriculum

**Approach:** Progressive learning - build components incrementally, understand each piece before moving forward

**Balance:** 30% Theory + 70% Hands-On

**Target Audience:** Data engineering students with Python knowledge, minimal Docker experience

---

## ðŸŽ¯ Learning Outcomes

By the end of 6 hours, students will:
- âœ… Understand Kafka architecture and core concepts
- âœ… Build a producer from scratch (not just copy-paste)
- âœ… Write ksqlDB queries for real-time stream processing
- âœ… Configure Kafka Connect to export data to Azure Blob Storage
- âœ… Monitor and troubleshoot a complete streaming pipeline
- âœ… Adapt the pipeline for their own use cases

---

## ðŸ“š Module Breakdown (6 Hours Total)

### Module 1: Kafka Fundamentals (60 minutes)
**Theory: 20 min | Hands-On: 40 min**

**Theory Topics:**
- What is event streaming? (vs traditional databases)
- Apache Kafka architecture overview
- Topics, partitions, and offsets explained
- Use cases and industry applications

**Hands-On Lab:**
- Set up minimal Kafka cluster (Zookeeper + Kafka only)
- Create topics using CLI commands
- Send messages using console producer
- Consume messages using console consumer
- Understand topic configuration (partitions, replication)

**Docker Stack:** 2 containers (Zookeeper, Kafka)

**Exercises:**
- Create a topic with 3 partitions
- Send 100 test messages
- Observe message distribution across partitions
- Check offsets and consumer lag

**Deliverables:**
- `theory/01-what-is-kafka.md`
- `theory/02-architecture-overview.md` (with Mermaid diagrams)
- `theory/03-topics-partitions-offsets.md`
- `lab/README.md` (step-by-step setup)
- `lab/docker-compose.yml` (minimal: Zookeeper + Kafka)
- `lab/exercises.md`

---

### Module 2: Producers & Consumers (75 minutes)
**Theory: 25 min | Hands-On: 50 min**

**Theory Topics:**
- Producer architecture and message flow
- Message delivery guarantees (at-most-once, at-least-once, exactly-once)
- Consumer groups and partition assignment
- Offset management and commit strategies
- Serialization formats (JSON, Avro)

**Hands-On Lab:**
- Build a simple producer from scratch (step-by-step)
- Add error handling and retries
- Build the vehicle IoT simulator (10 vehicles)
- Implement realistic data generation (GPS, speed, fuel, temp)
- Create a consumer to read and process messages
- Experiment with consumer groups

**Docker Stack:** 3 containers (Zookeeper, Kafka, Producer container)

**Exercises:**
- Modify producer to add new field (vehicle_type: sedan/truck)
- Change message rate (1/sec â†’ 5/sec) and observe
- Create 2 consumers in same group, observe load balancing
- Implement a simple alert consumer (print when speed > 80)

**Deliverables:**
- `theory/01-producer-architecture.md`
- `theory/02-consumer-groups.md`
- `theory/03-serialization.md`
- `lab/README.md` (build producer step-by-step)
- `lab/producer-simple.py` (basic example with comments)
- `lab/producer-vehicle.py` (full IoT simulator, copied from kafka/)
- `lab/consumer-simple.py` (basic consumer example)
- `lab/Dockerfile.producer`
- `lab/requirements.txt`
- `lab/exercises.md`

---

### Module 3: Stream Processing with ksqlDB (90 minutes)
**Theory: 30 min | Hands-On: 60 min**

**Theory Topics:**
- Why stream processing? (vs batch processing)
- Stream processing patterns (filtering, transformation, aggregation, joins)
- ksqlDB overview (SQL for streams)
- Streams vs Tables in ksqlDB
- Windowing and time semantics

**Hands-On Lab:**
- Add ksqlDB to docker-compose
- Access ksqlDB CLI
- Create base stream from vehicle.telemetry topic
- Write filtering queries (speeding alerts: speed > 80)
- Write aggregation queries (1-minute statistics per vehicle)
- Create derived streams (low fuel alerts, overheating alerts)
- Query streams in real-time

**Docker Stack:** 5 containers (Zookeeper, Kafka, Producer, ksqlDB Server, ksqlDB CLI)

**Exercises:**
- Write query to detect harsh braking (speed drops > 30 km/h in 5 seconds)
- Create hourly aggregation (avg speed, max speed per vehicle per hour)
- Debug a failing query (intentionally broken example)
- Combine multiple streams (all alerts in one stream)

**Known Issue:** ksqlDB might have issues - document workaround (direct telemetry â†’ blob)

**Deliverables:**
- `theory/01-why-stream-processing.md`
- `theory/02-ksqldb-overview.md`
- `theory/03-streams-vs-tables.md`
- `theory/04-windowing-time.md`
- `lab/README.md` (setup ksqlDB step-by-step)
- `lab/docker-compose.yml` (add ksqlDB components)
- `lab/queries/01-create-base-stream.sql`
- `lab/queries/02-filtering-speeding.sql`
- `lab/queries/03-aggregations.sql`
- `lab/queries/04-derived-streams.sql`
- `lab/setup_streams.sh` (automated setup script)
- `lab/exercises.md`

---

### Module 4: Kafka Connect & Data Integration (60 minutes)
**Theory: 20 min | Hands-On: 40 min**

**Theory Topics:**
- What is Kafka Connect? (vs writing custom code)
- Source connectors vs Sink connectors
- Connector architecture and workers
- Configuration parameters explained
- Common connectors (JDBC, S3, Blob Storage, Elasticsearch, etc.)

**Hands-On Lab:**
- Add Kafka Connect to docker-compose
- Install Azure Blob Storage connector plugin
- Configure Azure Storage Account (create in portal)
- Create blob container
- Configure connector (account name, key, container, partitioning)
- Deploy connector using REST API
- Verify data flowing to Azure (JSON files in hourly folders)
- Check time-based partitioning (year/month/day/hour)

**Docker Stack:** 7 containers (full stack + Schema Registry + Kafka Connect)

**Exercises:**
- Change partition format from hourly to daily
- Modify flush size (10 â†’ 100 messages) and observe
- Check Azure storage structure, download files
- Configure connector for different topic (vehicle.speeding only)

**Deliverables:**
- `theory/01-what-is-kafka-connect.md`
- `theory/02-source-vs-sink.md`
- `theory/03-connector-configuration.md`
- `lab/README.md` (Azure setup + connector deployment)
- `lab/docker-compose.yml` (full stack)
- `lab/config/azure-blob-sink.json`
- `lab/config/azure-credentials.env.example`
- `lab/scripts/deploy_connector.sh`
- `lab/scripts/verify_connector.sh`
- `lab/azure-setup-guide.md` (portal walkthrough with screenshots)
- `lab/exercises.md`

---

### Module 5: Monitoring & Operations (45 minutes)
**Theory: 15 min | Hands-On: 30 min**

**Theory Topics:**
- Key Kafka metrics (throughput, latency, consumer lag)
- Monitoring tools (Control Center, Prometheus, Grafana)
- Common failure scenarios
- Debugging strategies
- Log analysis techniques

**Hands-On Lab:**
- Add Control Center to docker-compose
- Navigate Control Center UI (topics, producers, consumers, connectors)
- Monitor message flow in real-time
- Check consumer lag
- View connector status and errors
- Read Kafka logs
- Troubleshooting exercises (intentionally break things)

**Docker Stack:** 8 containers (full stack + Control Center)

**Exercises:**
- Stop producer, observe lag, restart producer
- Stop ksqlDB, see what happens, restart
- Misconfigure connector (wrong Azure key), diagnose, fix
- Find slow consumer, identify bottleneck
- Monitor disk usage and message retention

**Deliverables:**
- `theory/01-monitoring-metrics.md`
- `theory/02-troubleshooting-strategies.md`
- `lab/README.md` (Control Center walkthrough)
- `lab/docker-compose.yml` (add Control Center)
- `lab/control-center-guide.md` (UI navigation with screenshots)
- `lab/common-issues.md` (error patterns + solutions)
- `lab/exercises.md` (break and fix scenarios)

---

### Module 6: End-to-End Production Pipeline (60 minutes)
**Theory: 15 min | Hands-On: 45 min**

**Theory Topics:**
- Production readiness checklist
- Scaling Kafka (adding brokers, partitions, replication)
- High availability and fault tolerance
- Security basics (authentication, encryption)
- Real-world use cases (Uber, Netflix, LinkedIn)
- Cost considerations
- Next steps (Confluent Cloud, certifications, career paths)

**Hands-On Lab:**
- Deploy complete 8-service stack
- Run end-to-end pipeline (producer â†’ Kafka â†’ ksqlDB â†’ Connect â†’ Azure)
- Verify data flow at each stage
- Download data from Azure Blob Storage
- (Optional) Create Power BI dashboard
- Capstone challenge: Adapt pipeline for different use case

**Docker Stack:** 8 containers (full production-like stack)

**Capstone Challenge Options:**
1. Smart Home IoT (temperature, humidity, energy usage sensors)
2. E-commerce Order Processing (orders, payments, shipments)
3. Financial Transactions (fraud detection, real-time analytics)
4. Social Media Feed (posts, likes, comments streaming)

**Deliverables:**
- `theory/01-production-considerations.md`
- `theory/02-scaling-kafka.md`
- `theory/03-real-world-use-cases.md`
- `theory/04-next-steps.md`
- `lab/README.md` (complete deployment guide)
- `lab/docker-compose.yml` (full production stack)
- `lab/IMPLEMENTATION_GUIDE.md` (adapted from kafka/IMPLEMENTATION_GUIDE.md)
- `lab/verify_setup.sh`
- `lab/capstone-challenge.md`
- `lab/power-bi-guide.md` (optional dashboard creation)

---

## ðŸ“ Folder Structure

```
kafka-tutorials/
â”œâ”€â”€ README.md                          # Main curriculum overview (532 lines - already created)
â”œâ”€â”€ CURRICULUM_PLAN.md                 # This file (detailed plan)
â”‚
â”œâ”€â”€ module-1-kafka-fundamentals/       # 60 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-what-is-kafka.md
â”‚   â”‚   â”œâ”€â”€ 02-architecture-overview.md
â”‚   â”‚   â””â”€â”€ 03-topics-partitions-offsets.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Minimal: Zookeeper + Kafka
â”‚       â””â”€â”€ exercises.md
â”‚
â”œâ”€â”€ module-2-producers-consumers/      # 75 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-producer-architecture.md
â”‚   â”‚   â”œâ”€â”€ 02-consumer-groups.md
â”‚   â”‚   â””â”€â”€ 03-serialization.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Add producer container
â”‚       â”œâ”€â”€ producer-simple.py
â”‚       â”œâ”€â”€ producer-vehicle.py        # From kafka/producer.py
â”‚       â”œâ”€â”€ consumer-simple.py
â”‚       â”œâ”€â”€ Dockerfile.producer
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ exercises.md
â”‚
â”œâ”€â”€ module-3-stream-processing/        # 90 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-why-stream-processing.md
â”‚   â”‚   â”œâ”€â”€ 02-ksqldb-overview.md
â”‚   â”‚   â”œâ”€â”€ 03-streams-vs-tables.md
â”‚   â”‚   â””â”€â”€ 04-windowing-time.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Add ksqlDB Server + CLI
â”‚       â”œâ”€â”€ queries/
â”‚       â”‚   â”œâ”€â”€ 01-create-base-stream.sql
â”‚       â”‚   â”œâ”€â”€ 02-filtering-speeding.sql
â”‚       â”‚   â”œâ”€â”€ 03-aggregations.sql
â”‚       â”‚   â””â”€â”€ 04-derived-streams.sql
â”‚       â”œâ”€â”€ setup_streams.sh
â”‚       â””â”€â”€ exercises.md
â”‚
â”œâ”€â”€ module-4-kafka-connect/            # 60 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-what-is-kafka-connect.md
â”‚   â”‚   â”œâ”€â”€ 02-source-vs-sink.md
â”‚   â”‚   â””â”€â”€ 03-connector-configuration.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Add Connect + Schema Registry
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ azure-blob-sink.json
â”‚       â”‚   â””â”€â”€ azure-credentials.env.example
â”‚       â”œâ”€â”€ scripts/
â”‚       â”‚   â”œâ”€â”€ deploy_connector.sh
â”‚       â”‚   â””â”€â”€ verify_connector.sh
â”‚       â”œâ”€â”€ azure-setup-guide.md
â”‚       â””â”€â”€ exercises.md
â”‚
â”œâ”€â”€ module-5-monitoring-operations/    # 45 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-monitoring-metrics.md
â”‚   â”‚   â””â”€â”€ 02-troubleshooting-strategies.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Add Control Center
â”‚       â”œâ”€â”€ control-center-guide.md
â”‚       â”œâ”€â”€ common-issues.md
â”‚       â””â”€â”€ exercises.md
â”‚
â”œâ”€â”€ module-6-end-to-end-pipeline/      # 60 minutes
â”‚   â”œâ”€â”€ theory/
â”‚   â”‚   â”œâ”€â”€ 01-production-considerations.md
â”‚   â”‚   â”œâ”€â”€ 02-scaling-kafka.md
â”‚   â”‚   â”œâ”€â”€ 03-real-world-use-cases.md
â”‚   â”‚   â””â”€â”€ 04-next-steps.md
â”‚   â””â”€â”€ lab/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ docker-compose.yml         # Full 8-service stack
â”‚       â”œâ”€â”€ IMPLEMENTATION_GUIDE.md    # From kafka/IMPLEMENTATION_GUIDE.md
â”‚       â”œâ”€â”€ verify_setup.sh
â”‚       â”œâ”€â”€ capstone-challenge.md
â”‚       â””â”€â”€ power-bi-guide.md
â”‚
â””â”€â”€ reference/
    â”œâ”€â”€ quick-commands.md              # Cheat sheet
    â”œâ”€â”€ troubleshooting.md             # Comprehensive guide
    â”œâ”€â”€ glossary.md                    # Kafka terminology
    â””â”€â”€ next-steps.md                  # After the course
```

---

## ðŸ”„ Content Migration Strategy

### From kafka/ folder â†’ kafka-tutorials/ modules

| Source File | Destination | Transformation |
|-------------|-------------|----------------|
| `kafka/QUICKSTART.md` | Module 6 `lab/README.md` | Simplify, focus on verification |
| `kafka/PROJECT_DOCUMENTATION.md` | Split across all `theory/` folders | Extract sections, add diagrams |
| `kafka/IMPLEMENTATION_GUIDE.md` | Module 6 `lab/IMPLEMENTATION_GUIDE.md` | Adapt for full pipeline |
| `kafka/docker-compose.yml` | Progressive versions in each module | Split into 6 incremental versions |
| `kafka/producer.py` | Module 2 `lab/producer-vehicle.py` | Add inline comments, explain logic |
| `kafka/scripts/ksqldb_setup.sql` | Module 3 `lab/queries/*.sql` | Split into separate query files |
| `kafka/config/azure-blob-sink.json` | Module 4 `lab/config/` | Add explanatory comments |
| `kafka/scripts/deploy_azure_connector.sh` | Module 4 `lab/scripts/` | Add verbose output, error handling |
| `kafka/scripts/verify_setup.sh` | Module 6 `lab/verify_setup.sh` | Adapt for full stack |
| `kafka/CODESPACES.md` | Module 4 `lab/` (note section) | Reference for ARM64 issues |

---

## ðŸŽ¨ Visual Materials (Recommended)

### Mermaid Diagrams (Render in Markdown)

**Module 1:**
- Kafka architecture diagram (brokers, topics, partitions)
- Message flow (producer â†’ broker â†’ consumer)
- Partition leadership diagram

**Module 2:**
- Producer message flow with acknowledgments
- Consumer group partition assignment
- Offset management illustration

**Module 3:**
- Stream processing pipeline
- ksqlDB architecture
- Windowing visualization

**Module 4:**
- Kafka Connect architecture
- Connector deployment flow
- Azure Blob Storage partitioning structure

**Module 5:**
- Monitoring architecture
- Failure scenarios flowchart

**Module 6:**
- Complete end-to-end pipeline
- Scaling strategies (horizontal, vertical)

### Screenshots (Optional for Video Creators)

- Azure Portal: Storage account creation steps
- Azure Portal: Blob container navigation
- Control Center: Topics page
- Control Center: Consumers page with lag
- Control Center: Connect page with connector status
- ksqlDB CLI: Query execution
- Power BI: Dashboard examples

---

## â±ï¸ Detailed Time Breakdown

### Module 1 (60 min)
- 00:00-05:00 - What is event streaming?
- 05:00-10:00 - Kafka architecture overview
- 10:00-20:00 - Topics, partitions, offsets
- 20:00-30:00 - Docker setup (Zookeeper + Kafka)
- 30:00-40:00 - Create topics, send/receive messages
- 40:00-50:00 - Exercises (hands-on practice)
- 50:00-60:00 - Q&A and verification

### Module 2 (75 min)
- 00:00-10:00 - Producer architecture
- 10:00-15:00 - Message delivery guarantees
- 15:00-25:00 - Consumer groups and offsets
- 25:00-35:00 - Build simple producer (step-by-step)
- 35:00-50:00 - Build vehicle IoT simulator
- 50:00-60:00 - Build simple consumer
- 60:00-70:00 - Exercises (modify producer/consumer)
- 70:00-75:00 - Q&A

### Module 3 (90 min)
- 00:00-10:00 - Why stream processing?
- 10:00-20:00 - ksqlDB overview
- 20:00-30:00 - Streams vs tables, windowing
- 30:00-40:00 - Setup ksqlDB in Docker
- 40:00-50:00 - Create base stream
- 50:00-60:00 - Filtering queries (speeding, low fuel)
- 60:00-70:00 - Aggregation queries (1-min stats)
- 70:00-80:00 - Exercises (write custom queries)
- 80:00-90:00 - Q&A and troubleshooting

### Module 4 (60 min)
- 00:00-10:00 - What is Kafka Connect?
- 10:00-20:00 - Connector architecture
- 20:00-35:00 - Azure setup (storage account, container, keys)
- 35:00-45:00 - Deploy connector, configure
- 45:00-50:00 - Verify data in Azure Blob Storage
- 50:00-55:00 - Exercises (modify configuration)
- 55:00-60:00 - Q&A

### Module 5 (45 min)
- 00:00-05:00 - Key Kafka metrics
- 05:00-15:00 - Monitoring tools and strategies
- 15:00-25:00 - Control Center walkthrough
- 25:00-35:00 - Troubleshooting exercises (break and fix)
- 35:00-40:00 - Log analysis
- 40:00-45:00 - Q&A

### Module 6 (60 min)
- 00:00-05:00 - Production readiness checklist
- 05:00-10:00 - Scaling strategies
- 10:00-15:00 - Real-world use cases, next steps
- 15:00-30:00 - Deploy complete pipeline
- 30:00-40:00 - End-to-end verification
- 40:00-55:00 - Capstone challenge (adapt for new use case)
- 55:00-60:00 - Course wrap-up, Q&A

**Total: 390 minutes (6.5 hours including buffer)**

---

## ðŸŽ“ Pedagogical Principles

### 1. Progressive Complexity
- Start simple (just Kafka), add components incrementally
- Each module builds on previous knowledge
- Don't overwhelm with full stack on day 1

### 2. Hands-On First
- Theory explains "why," labs show "how"
- Students type commands, don't just watch
- Make mistakes, troubleshoot, learn from errors

### 3. Real-World Context
- Every concept tied to industry use case
- Show actual company examples (Uber, Netflix, etc.)
- Explain job skills and career paths

### 4. Verification Checkpoints
- After each step: "You should see..."
- "If you see X, something is wrong - here's how to fix"
- Regular validation prevents students getting lost

### 5. Incremental Learning
- Introduce concepts just-in-time (when needed)
- Don't explain everything upfront
- Let curiosity drive deeper learning

---

## âœ… Success Criteria

### For Students
After completing the course, students should be able to:

**Knowledge (Can Explain):**
- âœ… What Kafka is and why companies use it
- âœ… How topics, partitions, and offsets work
- âœ… The difference between batch and stream processing
- âœ… How Kafka Connect simplifies data integration

**Skills (Can Do):**
- âœ… Set up a Kafka cluster using Docker
- âœ… Write a producer from scratch in Python
- âœ… Write ksqlDB queries to filter and aggregate streams
- âœ… Deploy a Kafka Connect connector
- âœ… Monitor and troubleshoot a Kafka pipeline

**Application (Can Build):**
- âœ… Adapt the vehicle pipeline for a different IoT use case
- âœ… Design an event-driven architecture for a business problem
- âœ… Make production readiness decisions (partitions, replication, etc.)

### For Instructors
- âœ… Clear teaching flow (theory â†’ demo â†’ practice)
- âœ… All materials provided (no prep work needed)
- âœ… Exercises with solutions
- âœ… Common student questions anticipated and addressed

---

## ðŸš€ Implementation Plan

### Phase 1: Create Module Skeletons (Day 1)
- âœ… Create folder structure for all 6 modules
- âœ… Create theory/ and lab/ subdirectories
- âœ… Create placeholder README.md files

### Phase 2: Build Theory Content (Day 2-3)
- âœ… Write 20+ theory markdown files
- âœ… Add Mermaid diagrams
- âœ… Extract content from PROJECT_DOCUMENTATION.md
- âœ… Add industry examples and use cases

### Phase 3: Build Lab Content (Day 4-5)
- âœ… Create 6 progressive docker-compose.yml files
- âœ… Write step-by-step lab README files
- âœ… Copy and adapt code from kafka/ folder
- âœ… Create exercises with solutions

### Phase 4: Build Scripts and Automation (Day 6)
- âœ… Create setup scripts for each module
- âœ… Create verification scripts
- âœ… Test end-to-end on clean machine

### Phase 5: Create Reference Materials (Day 7)
- âœ… Write quick-commands.md cheat sheet
- âœ… Write comprehensive troubleshooting guide
- âœ… Write glossary of Kafka terms
- âœ… Write next-steps guide

### Phase 6: Review and Polish (Day 8)
- âœ… Test all commands and code
- âœ… Fix broken links
- âœ… Proofread all content
- âœ… Get peer review

---

## ðŸ“Š Metrics for Success

### Student Metrics
- **Completion Rate:** >80% finish all 6 modules
- **Time to Complete:** 6-8 hours average
- **Quiz Scores:** >70% pass rate on knowledge checks
- **Capstone Success:** >60% complete custom adaptation

### Content Metrics
- **Code Quality:** All code runs without errors
- **Documentation Clarity:** <5% students stuck on same step
- **Exercise Difficulty:** Students spend 10-15 min per exercise (not too easy, not too hard)

### Instructor Metrics
- **Prep Time:** <1 hour to prepare for teaching
- **Q&A Volume:** <10% of class time spent on clarifications (content is clear)
- **Repeat Usage:** Instructors teach the course multiple times

---

## ðŸ› ï¸ Tools and Technologies

### Development Tools
- **Text Editor:** VS Code (with Markdown Preview, Mermaid extension)
- **Diagramming:** Mermaid (for architecture diagrams)
- **Version Control:** Git (track changes, branches per module)

### Testing Environment
- **OS:** Linux/macOS (primary), Windows (secondary)
- **Docker:** Version 20.10+
- **Python:** 3.8+
- **Azure:** Free tier sufficient

---

## ðŸ“ Content Guidelines

### Writing Style
- **Tone:** Friendly, encouraging, not condescending
- **Clarity:** Use simple language, define jargon
- **Brevity:** Keep theory sections to 5-10 min reads
- **Structure:** Use headers, bullets, code blocks consistently

### Code Style
- **Comments:** Explain "why," not just "what"
- **Naming:** Use descriptive variable names
- **Error Handling:** Always include try/catch with helpful messages
- **Logging:** Add print statements to show progress

### Exercise Design
- **Clear Objective:** "Your goal is to..."
- **Step-by-Step:** Break into numbered steps
- **Expected Output:** "You should see..."
- **Hints:** Provide hints before full solution
- **Extensions:** "Extra challenge: Try..."

---

## ðŸ”„ Maintenance Plan

### Regular Updates
- **Quarterly:** Update to latest Confluent Platform version
- **Bi-annually:** Review industry trends, add new use cases
- **Annually:** Major content refresh based on student feedback

### Community Contributions
- Accept pull requests for improvements
- Track common student questions â†’ add FAQ
- Share student capstone projects as examples

---

## ðŸ“ž Support Plan

### For Students
- **During Course:** Ask instructor (live) or check troubleshooting guide
- **After Course:** Confluent Community Slack, Stack Overflow
- **Issues/Bugs:** GitHub issues in repository

### For Instructors
- **Prep Support:** Instructor guide (detailed teaching notes)
- **Technical Issues:** Test environment setup guide
- **Content Questions:** Contact curriculum authors

---

## ðŸŽ‰ Next Steps

1. **Review and Approve This Plan** âœ…
2. **Start Building Module 1** â†’
3. **Test Module 1 with Pilot Students**
4. **Iterate Based on Feedback**
5. **Complete Remaining Modules**
6. **Pilot Full 6-Hour Course**
7. **Gather Feedback and Refine**
8. **Launch for Production Use**

---

## ðŸ“… Estimated Timeline

| Task | Duration | Owner |
|------|----------|-------|
| Plan approval | 1 day | Stakeholders |
| Module 1 build | 2 days | Content creator |
| Module 2 build | 2 days | Content creator |
| Module 3 build | 3 days | Content creator |
| Module 4 build | 2 days | Content creator |
| Module 5 build | 1 day | Content creator |
| Module 6 build | 2 days | Content creator |
| Reference materials | 1 day | Content creator |
| Testing and QA | 2 days | QA team |
| Pilot course | 1 day | Instructor + students |
| Refinements | 2 days | Content creator |
| **TOTAL** | **~3 weeks** | |

---

## ðŸ’¡ Key Insights

### Why This Structure Works
1. **Progressive Learning:** Don't overwhelm beginners with full stack
2. **Hands-On Focus:** 70% doing, 30% reading
3. **Real-World Relevance:** Vehicle IoT is relatable and practical
4. **Incremental Docker:** Add services one by one, understand each
5. **Verification:** Checkpoints ensure no one falls behind
6. **Adaptation:** Capstone lets students apply to their domain

### What Makes This Different
- Not just a tutorial (follow steps) - it's a curriculum (understand concepts)
- Not just copy-paste code - build from scratch
- Not just run Docker - understand each service
- Not just theory - hands-on practice at every step
- Not just one use case - learn to adapt

---

## âœ… Approval Checklist

Before proceeding to build:

- [ ] **Scope Confirmed:** 6 hours, 6 modules, hands-on focus
- [ ] **Audience Validated:** Data engineering students with Python knowledge
- [ ] **Tools Approved:** Docker, Python, Azure Blob Storage
- [ ] **Structure Agreed:** Separate folders per module, theory + lab
- [ ] **Timeline Accepted:** ~3 weeks to complete
- [ ] **Resources Allocated:** Content creator(s), QA tester(s)

---

## ðŸš¦ Ready to Build?

**Next Action:** Upon approval of this plan, begin building **Module 1: Kafka Fundamentals**

ðŸ‘‰ **Proceed to Module 1 Development** â†’

---

**Questions or Feedback?** Please provide comments on this plan before we start building.
