Vehicle IoT Real-Time Streaming Analytics Project Proposal
Using Kafka, Azure, and Power BI (Free Tools Edition)
 
1. Executive Summary
This proposal outlines a beginner-friendly data engineering project focused on building an end-to-end real-time analytics pipeline using open-source and free-tier tools. The project simulates live IoT data from vehicles, streams it via Apache Kafka, processes it with ksqlDB, stores results in Azure Blob Storage, and visualizes insights in Power BI Desktop.
Learners will gain practical experience in event streaming, cloud integration, and dashboarding — fundamental skills in modern data engineering.
 
2. Problem Statement
Modern connected vehicles continuously generate telemetry data — such as speed, fuel level, engine temperature, and GPS coordinates. Organizations require real-time analytics pipelines to monitor this data and trigger timely alerts (e.g., speeding, low fuel).
This project aims to demonstrate how to implement such a pipeline using Kafka for streaming, Azure Blob Storage for persistence, and Power BI for visualization, all leveraging free tools and services.















 
3. Project Objectives
#	Objective	Description
1	Understand Kafka Fundamentals	Learn how to produce, consume, and manage topics
2	Build a Streaming Pipeline	Deploy Kafka and ksqlDB using Docker
3	Simulate IoT Data	Stream vehicle telemetry using Python
4	Perform Real-Time Analytics	Filter and aggregate streams using ksqlDB
5	Store in Cloud	Sink processed data to Azure Blob Storage
6	Visualize Insights	Create dashboards in Power BI Desktop

 
4. Project Scope
In Scope
•	Local setup of Kafka, ksqlDB, and Kafka Connect
•	Python-based IoT simulator (Dockerized)
•	Azure Blob Storage integration via Kafka Connect
•	Power BI dashboard creation using Blob data
Out of Scope
•	Predictive ML models (future extension)
•	Power BI Service publishing (Pro license)
•	Enterprise-scale Kafka cluster deployment













 
5. System Architecture
Architecture Diagram
Below is a visual representation of the data pipeline:
 
Data Flow:
Python simulator → Apache Kafka → ksqlDB (stream processing) → Kafka Connect → Azure Blob Storage → Power BI Desktop
Components: 
-Producer: Python simulator generating vehicle telemetry 
- Broker: Apache Kafka for ingestion 
- Processor: ksqlDB for transformations and alerts 
- Sink: Kafka Connect (Azure Blob Storage Connector) 
- Visualization: Power BI Desktop dashboard



 
6. Implementation Timeline
Milestone Timeline Chart
Phase	Duration	Deliverables
Phase 1 – Environment Setup	Day 1	Docker Compose setup for Kafka, ksqlDB, Connect
Phase 2 – Data Simulation	Day 2	Python simulator generating telemetry
Phase 3 – Stream Processing	Days 3–4	ksqlDB queries for speeding & low fuel detection
Phase 4 – Azure Integration	Day 5	Kafka Connect → Azure Blob JSON files
Phase 5 – Visualization	Days 6–7	Power BI dashboard creation


 
7. Milestones
Milestone	Key Tasks	Deliverable
M1	Setup Kafka Environment	Functional local Kafka & ksqlDB cluster
M2	Create Data Simulator	Live IoT data streaming to Kafka topic
M3	Implement Stream Queries	Speeding & Low Fuel detection streams
M4	Store in Azure Blob	Processed data written to cloud storage
M5	Power BI Dashboard	Visualization of live analytics









 
8. Learning Outcomes
Category	Skill Developed	Outcome
Kafka Fundamentals	Topic management, message flow	Functional event streaming setup
Stream Processing	SQL over streams with ksqlDB	Real-time alerts & aggregates
Azure Integration	Blob Sink Connector setup	Cloud data persistence
Visualization	Power BI Dashboarding	Interactive real-time insights
End-to-End Design	Full data pipeline integration	Operational streaming project
 
9. Sample ksqlDB Queries
CREATE STREAM vehicle_stream (
  vehicle_id VARCHAR,
  timestamp_utc VARCHAR,
  location STRUCT<lat DOUBLE, lon DOUBLE>,
  speed_kmph DOUBLE,
  fuel_percent DOUBLE,
  engine_temp_c DOUBLE,
  status VARCHAR
) WITH (KAFKA_TOPIC='vehicle.telemetry', VALUE_FORMAT='JSON');

CREATE STREAM speeding_stream AS
SELECT vehicle_id, speed_kmph, timestamp_utc
FROM vehicle_stream
WHERE speed_kmph > 80;

CREATE STREAM lowfuel_stream AS
SELECT vehicle_id, fuel_percent, timestamp_utc
FROM vehicle_stream
WHERE fuel_percent < 15;
 
10. Power BI Dashboard Design
Dashboard Mockup
 
Dashboard Pages: 
1. Overview Page: Active Vehicles, Speeding Alerts, Fuel Levels 
2. Map Visualization: Vehicle locations plotted by coordinates 
3. Trend Analysis: Speed over time by vehicle 
4. Alert Summary: Low fuel and speeding records
Sample KPIs: - Total Vehicles Streamed - Number of Speeding Events - Average Fuel Level
 
11. Resources & Tools
Component	Tool	Cost
Container Runtime	Docker Desktop	Free
Data Stream	Apache Kafka	Free
Stream Processing	ksqlDB	Free
Cloud Storage	Azure Blob (Free Tier)	Free
Dashboarding	Power BI Desktop	Free
Coding	Python 3.x + VS Code	Free
 
12. Evaluation Criteria
Category	Weight	Description
Kafka Setup	20%	Services up and running
Data Simulation	20%	Continuous IoT message streaming
Stream Processing	20%	Correct transformation logic
Azure Integration	20%	Data correctly stored in Blob
Dashboard Design	20%	Insightful visuals & KPIs
 
13. Risk & Mitigation
Risk	Cause	Mitigation
Port Conflicts	Docker service overlap	Change ports (e.g., 29092)
Azure Auth Errors	Invalid access key	Use verified connection string
Slow Stream Rate	Excess event rate	Limit producer frequency
Power BI Errors	File format mismatch	Use JSON/CSV exports
 
14. Success Criteria
Technical: - Kafka + ksqlDB + Connect operational locally - Data visible in Power BI Dashboard
Educational: - Learners understand the complete streaming pipeline - Participants can replicate setup independently


 
15. Future Enhancements
•	Integration with Azure Synapse or Databricks for warehousing
•	Use Azure Event Hubs as managed Kafka service
•	Add ML model for predictive maintenance
•	Publish dashboards to Power BI Service (Pro)
 
16. Conclusion
This project offers a complete yet approachable hands-on experience in modern data engineering. Using only free and open tools, learners gain exposure to event streaming, real-time analytics, cloud data storage, and dashboarding — a practical foundation for building scalable analytics systems.

